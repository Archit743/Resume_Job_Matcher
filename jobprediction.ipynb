{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:34: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:37: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:36: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:37: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_23828\\1375479786.py:34: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_23828\\1375479786.py:36: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_23828\\1375479786.py:37: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  cleanText = re.sub('@\\S+', ' ', cleanText)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_23828\\1375479786.py:40: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  cleanText = re.sub('\\s+', ' ', cleanText)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Category Distribution:\n",
      "Category\n",
      "Java Developer               84\n",
      "Testing                      70\n",
      "DevOps Engineer              55\n",
      "Python Developer             48\n",
      "Web Designing                45\n",
      "HR                           44\n",
      "Hadoop                       42\n",
      "Sales                        40\n",
      "Data Science                 40\n",
      "Mechanical Engineer          40\n",
      "ETL Developer                40\n",
      "Blockchain                   40\n",
      "Operations Manager           40\n",
      "Arts                         36\n",
      "Database                     33\n",
      "Health and fitness           30\n",
      "PMO                          30\n",
      "Electrical Engineering       30\n",
      "Business Analyst             28\n",
      "DotNet Developer             28\n",
      "Automation Testing           26\n",
      "Network Security Engineer    25\n",
      "Civil Engineer               24\n",
      "SAP Developer                24\n",
      "Advocate                     20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced Category Distribution (After Oversampling):\n",
      "Category\n",
      "Java Developer               84\n",
      "Blockchain                   84\n",
      "PMO                          84\n",
      "Python Developer             84\n",
      "DevOps Engineer              84\n",
      "Health and fitness           84\n",
      "HR                           84\n",
      "SAP Developer                84\n",
      "Civil Engineer               84\n",
      "Automation Testing           84\n",
      "Hadoop                       84\n",
      "Mechanical Engineer          84\n",
      "Web Designing                84\n",
      "Testing                      84\n",
      "DotNet Developer             84\n",
      "Advocate                     84\n",
      "Business Analyst             84\n",
      "Arts                         84\n",
      "Sales                        84\n",
      "ETL Developer                84\n",
      "Operations Manager           84\n",
      "Network Security Engineer    84\n",
      "Data Science                 84\n",
      "Electrical Engineering       84\n",
      "Database                     84\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_23828\\1375479786.py:27: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_df = df.groupby('Category').apply(lambda x: x.sample(max_size, replace=True)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
    "\n",
    "# Check original category distribution\n",
    "print(\"Original Category Distribution:\")\n",
    "print(df['Category'].value_counts())\n",
    "\n",
    "# Oversampling\n",
    "max_size = df['Category'].value_counts().max()\n",
    "balanced_df = df.groupby('Category').apply(lambda x: x.sample(max_size, replace=True)).reset_index(drop=True)\n",
    "df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "print(\"\\nBalanced Category Distribution (After Oversampling):\")\n",
    "print(df['Category'].value_counts())\n",
    "\n",
    "# Text cleaning function\n",
    "def cleanResume(txt):\n",
    "    cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
    "    cleanText = re.sub('RT|cc', ' ', cleanText)\n",
    "    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
    "    cleanText = re.sub('@\\S+', ' ', cleanText)\n",
    "    cleanText = re.sub('[%s]' % re.escape(\"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"), ' ', cleanText)\n",
    "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText)\n",
    "    cleanText = re.sub('\\s+', ' ', cleanText)\n",
    "    return cleanText\n",
    "\n",
    "df['Resume'] = df['Resume'].apply(lambda x: cleanResume(x))\n",
    "\n",
    "# Encode categories\n",
    "le = LabelEncoder()\n",
    "df['Category'] = le.fit_transform(df['Category'])\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(df['Resume'])\n",
    "requredText = tfidf.transform(df['Resume'])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(requredText, df['Category'], test_size=0.2, random_state=42)\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()\n",
    "\n",
    "# Model training\n",
    "svc_model = OneVsRestClassifier(SVC())\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Save models\n",
    "pickle.dump(tfidf, open('tfidf.pkl', 'wb'))\n",
    "pickle.dump(svc_model, open('clf.pkl', 'wb'))\n",
    "pickle.dump(le, open('encoder.pkl', 'wb'))\n",
    "\n",
    "# Prediction function\n",
    "def pred(input_resume):\n",
    "    cleaned_text = cleanResume(input_resume)\n",
    "    vectorized_text = tfidf.transform([cleaned_text]).toarray()\n",
    "    predicted_category = svc_model.predict(vectorized_text)\n",
    "    return le.inverse_transform(predicted_category)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
